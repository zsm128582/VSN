## 研究课题
    
## 项目背景

## 技术实现

## 核心创新

## 性能指标

1. 针对transformer复杂度随token数量平方上涨的特点，提出了图像的稀疏注意力。
2. 由于pytorch原生实现需要使用unfold、gather等函数，消耗过多显存，所以编写了cuda算子融合，通过优化内存访问，大幅降低显存消耗
3. 不连续的token和transformer对输入顺序不敏感的特点，要求我们需要注重token位置编码。提出了可学习的将Rope应用到二维图像中。（使用了傅里叶变换和逆傅里叶变换验证效果）
4. 使用SVD分解验证投影矩阵的低秩特性与模型效果之间的关系，使用loss控制模型的秩。


项目课题：
项目描述：
在计算机视觉领域，视觉Transformer的注意力机制存在计算复杂度高、内存占用大的问题。本项目旨在提出一种动态、查询感知的稀疏注意力机制，实现计算资源的高效分配，提升模型在密集预测任务中的性能。








# 项目名称：BiFormer: Vision Transformer with Bi-Level Routing Attention
## 项目背景
在计算机视觉领域，视觉Transformer的注意力机制虽能捕捉长距离依赖，但存在计算复杂度高、内存占用大的问题。本项目旨在提出一种动态、查询感知的稀疏注意力机制，实现计算资源的高效分配，提升模型在密集预测任务中的性能。



## 技术内容
- **双层路由注意力机制（BRA）**
    - **区域级路由**：将特征图划分为S×S个非重叠区域，通过区域级查询和键的平均池化构建亲和图，筛选每个区域最相关的top-k区域，实现粗粒度的无关区域过滤。
    - **Token级注意力**：在筛选后的k个区域内，通过收集键值对（Key/Value Gathering）进行密集矩阵乘法，避免稀疏操作的GPU低效问题，实现细粒度的Token间交互，并引入深度卷积增强局部上下文。
    - **复杂度优化**：通过数学推导证明，当区域划分因子S按输入分辨率动态调整时，BRA的计算复杂度可降至O((HW)^(4/3))，显著低于传统全局注意力的O((HW)^2)。
- **BiFormer架构设计**
    - 采用四阶段金字塔结构，通过重叠补丁嵌入和补丁合并模块逐步降低空间分辨率、增加通道数。
    - 每个BiFormer块集成3×3深度卷积进行位置编码，依次连接BRA模块和MLP模块，平衡局部细节与全局依赖建模。

## 个人贡献
- 主导双层路由注意力机制的算法设计，提出区域级筛选与Token级密集计算结合的高效框架，解决传统稀疏注意力在GPU上的性能瓶颈。
- 设计BiFormer的层次化网络架构，优化模块配置（如深度卷积位置编码、MLP扩展比），提升模型在多任务中的泛化能力。
- 负责复杂度分析与数学推导，验证BRA在理论上的计算效率优势。
- 参与ImageNet、COCO、ADE20K等数据集的训练与实验验证，优化训练策略（如数据增强、正则化技术），实现模型在分类、检测、分割任务上的SOTA性能。
- 主导代码开源与文档撰写，确保算法的可复现性与工程落地可行性。

## 项目成果
- **学术发表**：论文发表于计算机视觉顶级会议CVPR，开源代码获广泛关注（GitHub链接：https://github.com/rayleizhu/BiFormer）。
- **性能突破**
    - **ImageNet分类**：BiFormer-S在4.5G FLOPs下实现83.8% Top-1准确率，优于同计算量下的Swin-T、CSWin-T等主流模型。
    - **COCO检测与分割**：在RetinaNet和Mask R-CNN框架下，BiFormer-B的mAP分别达到47.1%和48.6%，尤其在小物体检测上优势显著（AP_M提升3.0%+）。
    - **ADE20K语义分割**：基于UperNet框架，BiFormer-B实现51.7% mIoU，超越Swin Transformer、CSWin等基线模型。
- **方法论创新**：提出查询感知的动态稀疏注意力范式，为高效视觉Transformer设计提供新思路，相关技术可迁移至遥感图像分析、视频理解等领域。

## 技术亮点
动态稀疏注意力、双层路由机制、GPU友好型密集计算、层次化网络架构、多任务泛化能力。

## 备注
该项目完整展示了从问题定义、算法设计、理论分析到工程实现的全流程，重点体现了计算效率与模型性能的平衡，适用于计算机视觉、深度学习相关岗位的技术能力展示。